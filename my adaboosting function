rm(list=ls())
library(rpart)
library(adabag)
################################# data ##################################
mydata = read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
mydata[,4] = as.factor(mydata[,4])
train = mydata[1:200,]
test = mydata[201:400,]
train$admit2[train$admit==1] = 1
train$admit2[train$admit==0] = -1
test$admit2[test$admit==1] = 1
test$admit2[test$admit==0] = -1

tr.y = train[,5]
tr.x = train[,-c(1,5)]
te.y = test[,5]
te.x = test[-c(1,5)]
iter = 50
################################## Adaboost #############################
my.ada.fun = function(tr.y.vec,tr.x.mat,te.y.vec,te.x.mat,iter){
  n = length(tr.y.vec)
  iter = iter
  max.err = 0.5
  e.mat = matrix(NA,iter,n)
  w.vec = rep(1/n,n)
  c.vec = c()
  w.mat = matrix(NA,iter,n)
  tr.xy.df = data.frame(tr.y.vec,tr.x.mat)
  te.xy.df = data.frame(te.y.vec,te.x.mat)
  #train
  for(i in 1:iter){
    h = rpart(tr.y.vec~.,data = tr.xy.df,method="class",weights = w.vec,maxdepth=10)
    w.mat[i,] = w.vec
    h.pred = as.numeric(predict(h,tr.xy.df,type="class"))
    h.pred[h.pred==1] = -1 ; h.pred[h.pred==2] = 1
    e = sum(w.vec*(tr.y.vec!=h.pred))/sum(w.vec)
    c = log((1-e)/e)/2
    if(e>=max.err){ c = log((1-max.err)/max.err)/2 } #################
    if(e==0){ c = log((1-0.001)/0.001)/2 }
    c.vec = c(c.vec,c)
    i.vec = tr.y.vec==h.pred
    w.vec = w.vec*exp(c*(1-i.vec))/sum(w.vec)
    e.mat[i,] = c*h.pred
  }
  
  #train strong classifier
  train.clf = colSums(e.mat) 
  
  #test
  pred.mat = matrix(NA,iter,length(te.y.vec))
  for(i in 1:iter){
    h = rpart(tr.y.vec~.,data = tr.xy.df,method="class",weights = w.mat[i,],maxdepth=10)
    h.pred = as.numeric(predict(h,te.xy.df,type="class"))
    h.pred[h.pred==1] = -1 ; h.pred[h.pred==2] = 1
    pred.mat[i,] = c.vec[i]*h.pred
  }
  
  #test strong classifier
  test.clf = colSums(pred.mat)
  A = list(train.clf,test.clf)
  names(A) = c("train.clf","test.clf")
  return(A)
}

v = my.ada.fun(tr.y,tr.x,te.y,te.x,iter)
v$train.clf


############################################################################## 
comp.mat = matrix(NA,2,2) 
colnames(comp.mat) = c("myadaboost","boosting")
rownames(comp.mat) = c("train.acc","test.acc")

#myadaboost train, test acc
comp.mat[1,1] = mean(train$admit==ifelse(v$train.clf>0,1,0))
comp.mat[2,1] = mean(test$admit==ifelse(v$test.clf >0,1,0))

#boosting function train, test acc
train$admit=as.factor(train$admit)
test$admit=as.factor(test$admit)
boost = boosting(admit~gre+gpa+rank,data=train,boos = F,mfinal=iter,
                 control=rpart.control(maxdepth=10))
boost.train = predict.boosting(boost,newdata=train[,-5])
boost.test = predict.boosting(boost,newdata=test)
comp.mat[1,2] = mean(train$admit==boost.train$class)
comp.mat[2,2] = mean(test$admit==boost.test$class)


#compare
comp.mat




